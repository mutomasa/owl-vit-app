"""
OWL-ViTãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†ã‚’æ‹…å½“ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å˜ä¸€è²¬ä»»åŸå‰‡ã«å¾“ã„ã€ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã€æ¨è«–ã€å¾Œå‡¦ç†æ©Ÿèƒ½ã‚’æä¾›
"""

import torch
from typing import Optional, List, Dict, Any, Tuple
from transformers import AutoProcessor, OwlViTForObjectDetection
import streamlit as st


class ModelLoader:
    """ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    DEFAULT_MODEL_NAME = "google/owlvit-base-patch32"
    
    @staticmethod
    @st.cache_resource
    def load_model_and_processor(model_name: str = DEFAULT_MODEL_NAME) -> Tuple[Optional[OwlViTForObjectDetection], Optional[Any]]:
        """
        ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã™
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            
        Returns:
            (ãƒ¢ãƒ‡ãƒ«, ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼)ã®ã‚¿ãƒ—ãƒ«ã€å¤±æ•—æ™‚ã¯(None, None)
        """
        try:
            with st.spinner(f"ãƒ¢ãƒ‡ãƒ« '{model_name}' ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                processor = AutoProcessor.from_pretrained(model_name)
                model = OwlViTForObjectDetection.from_pretrained(model_name)
                return model, processor
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None, None
    
    @staticmethod
    def get_available_models() -> List[str]:
        """
        åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™
        
        Returns:
            åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã®ãƒªã‚¹ãƒˆ
        """
        return [
            "google/owlvit-base-patch32",
            "google/owlvit-base-patch16",
            "google/owlvit-large-patch14"
        ]


class TextQueryProcessor:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®å‡¦ç†ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def validate_text_queries(text_queries: List[str]) -> bool:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªãŒé©åˆ‡ã‹ã©ã†ã‹ã‚’æ¤œè¨¼ã—ã¾ã™
        
        Args:
            text_queries: æ¤œè¨¼ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªãŒé©åˆ‡ãªå ´åˆTrue
        """
        if not text_queries:
            st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return False
        
        for query in text_queries:
            if not query.strip():
                st.warning("ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã¯ä½¿ç”¨ã§ãã¾ã›ã‚“")
                return False
            
            if len(query.strip()) < 2:
                st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã¯2æ–‡å­—ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                return False
        
        return True
    
    @staticmethod
    def format_text_queries(text_queries: List[str], translation_method: str = "è¾æ›¸ç¿»è¨³ã®ã¿") -> List[List[str]]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’OWL-ViTã®å…¥åŠ›å½¢å¼ã«å¤‰æ›ã—ã¾ã™
        
        Args:
            text_queries: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
            translation_method: ç¿»è¨³æ–¹æ³•
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
        """
        from translator import JapaneseTranslator
        
        use_api = translation_method == "è¾æ›¸ç¿»è¨³ + APIç¿»è¨³"
        
        # å„å…ƒã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã€åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒªå½¢å¼ã®ã¿ã‚’ç”Ÿæˆ
        formatted_queries = []
        
        for query in text_queries:
            query = query.strip()
            
            # ã‚¯ã‚¨ãƒªãŒé•·ã™ãã‚‹å ´åˆã¯çŸ­ç¸®
            if len(query) > 50:
                query = query[:50]
                st.warning(f"ã‚¯ã‚¨ãƒªãŒé•·ã™ãã‚‹ãŸã‚ã€æœ€åˆã®50æ–‡å­—ã«çŸ­ç¸®ã—ã¾ã—ãŸ: {query}")
            
            # åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒªå½¢å¼ã®ã¿ã‚’ç”Ÿæˆ
            if JapaneseTranslator.is_japanese(query):
                # æ—¥æœ¬èªã®å ´åˆã€è‹±èªã«ç¿»è¨³
                english_translation = JapaneseTranslator.translate_japanese_to_english(query, use_api=use_api)
                if english_translation != query:
                    formatted_queries.append(f"a photo of a {english_translation}")
                else:
                    formatted_queries.append(f"a photo of a {query}")
            else:
                # è‹±èªã®å ´åˆã€åŸºæœ¬çš„ãªå½¢å¼
                formatted_queries.append(f"a photo of a {query}")
        
        # ã‚¯ã‚¨ãƒªã®æ•°ã‚’åˆ¶é™ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ï¼‰
        if len(formatted_queries) > 5:
            formatted_queries = formatted_queries[:5]
            st.warning(f"ã‚¯ã‚¨ãƒªã®æ•°ãŒå¤šã™ãã‚‹ãŸã‚ã€æœ€åˆã®5å€‹ã«åˆ¶é™ã—ã¾ã—ãŸ")
            
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
        if st.session_state.get('debug_mode', True):
            st.write(f"**ğŸ“ ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³:**")
            st.write(f"- å…ƒã®ã‚¯ã‚¨ãƒªæ•°: {len(text_queries)}")
            st.write(f"- ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªæ•°: {len(formatted_queries)}")
            for i, query in enumerate(formatted_queries):
                st.write(f"  {i+1}. '{query}'")
        
        # OWL-ViTã®æœŸå¾…ã™ã‚‹å½¢å¼: å„ã‚¯ã‚¨ãƒªã‚’å€‹åˆ¥ã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™
        return [[query] for query in formatted_queries]


class DetectionProcessor:
    """ç‰©ä½“æ¤œå‡ºã®å‡¦ç†ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def prepare_inputs(
        processor: Any,
        image: Any,
        text_queries: List[List[str]]
    ) -> Optional[Dict[str, Any]]:
        """
        ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã‚’æº–å‚™ã—ã¾ã™
        
        Args:
            processor: OWL-ViTãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
            image: å…¥åŠ›ç”»åƒ
            text_queries: ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
            
        Returns:
            æº–å‚™ã•ã‚ŒãŸå…¥åŠ›ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤ºï¼ˆæ¡ä»¶ä»˜ãï¼‰
            if st.session_state.get('debug_mode', True):
                st.write("**ğŸ” å…¥åŠ›æº–å‚™ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±:**")
                st.write(f"- å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªæ•°: {len(text_queries)}")
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®æ¤œè¨¼
            if not text_queries or not isinstance(text_queries, list):
                st.error("ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªãŒç„¡åŠ¹ã§ã™")
                return None
            
            # å„ã‚¯ã‚¨ãƒªãƒªã‚¹ãƒˆã‹ã‚‰æœ€åˆã®ã‚¯ã‚¨ãƒªã‚’å–å¾—
            normalized_queries = []
            for i, query_list in enumerate(text_queries):
                if isinstance(query_list, list) and len(query_list) > 0:
                    query = query_list[0]
                    if len(query) > 100:  # æœ€å¤§100æ–‡å­—ã«åˆ¶é™
                        query = query[:100]
                    normalized_queries.append(query)
                    if st.session_state.get('debug_mode', True):
                        st.write(f"- ã‚¯ã‚¨ãƒª {i+1}: '{query}'")
                else:
                    st.error("ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®å½¢å¼ãŒä¸æ­£ã§ã™")
                    return None
            
            if st.session_state.get('debug_mode', True):
                st.write(f"- æ­£è¦åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªæ•°: {len(normalized_queries)}")
            
            # OWL-ViTã®æ­£ã—ã„å…¥åŠ›å½¢å¼ã§å‡¦ç†
            # å„ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦åŒã˜ç”»åƒã‚’ä½¿ç”¨
            inputs = processor(
                text=normalized_queries,  # æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆ
                images=image,  # å˜ä¸€ã®ç”»åƒ
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=128
            )
            
            if st.session_state.get('debug_mode', True):
                st.write("âœ… å…¥åŠ›ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")
                if 'input_ids' in inputs:
                    st.write(f"- å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«ã®å½¢çŠ¶: {inputs['input_ids'].shape}")
            
            return inputs
        except Exception as e:
            st.error(f"å…¥åŠ›ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            st.write(f"ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®æ•°: {len(text_queries)}")
            for i, query_list in enumerate(text_queries):
                st.write(f"ã‚¯ã‚¨ãƒª {i+1} ã®é•·ã•: {len(query_list)}")
                st.write(f"ã‚¯ã‚¨ãƒª {i+1} ã®å†…å®¹: {query_list}")
            return None
    
    @staticmethod
    def run_inference(
        model: OwlViTForObjectDetection,
        inputs: Dict[str, Any]
    ) -> Optional[Any]:
        """
        æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™
        
        Args:
            model: OWL-ViTãƒ¢ãƒ‡ãƒ«
            inputs: ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›
            
        Returns:
            æ¨è«–çµæœã€å¤±æ•—æ™‚ã¯None
        """
        try:
            if st.session_state.get('debug_mode', True):
                st.write("**ğŸš€ æ¨è«–å®Ÿè¡Œä¸­...**")
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
            model.eval()
            
            with torch.no_grad():
                # ã‚·ãƒ³ãƒ—ãƒ«ãªæ¨è«–å®Ÿè¡Œ
                outputs = model(**inputs)
            
            # æ¨è«–çµæœã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            if st.session_state.get('debug_mode', True) and hasattr(outputs, 'logits'):
                logits_shape = outputs.logits.shape
                st.write(f"- ãƒ­ã‚¸ãƒƒãƒˆã®å½¢çŠ¶: {logits_shape}")
                
                # æœ€å¤§ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
                max_scores = torch.max(outputs.logits, dim=-1)[0]
                st.write(f"- æœ€å¤§ã‚¹ã‚³ã‚¢: {torch.max(max_scores).item():.4f}")
                st.write(f"- å¹³å‡ã‚¹ã‚³ã‚¢: {torch.mean(max_scores).item():.4f}")
            
            if st.session_state.get('debug_mode', True):
                st.write("âœ… æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return outputs
        except Exception as e:
            st.error(f"æ¨è«–ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            if st.session_state.get('debug_mode', True):
                st.write(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {str(e)}")
            return None
    
    @staticmethod
    def post_process_results(
        processor: Any,
        outputs: Any,
        target_sizes: torch.Tensor,
        confidence_threshold: float = 0.5
    ) -> Optional[List[Dict[str, Any]]]:
        """
        æ¨è«–çµæœã‚’å¾Œå‡¦ç†ã—ã¾ã™
        
        Args:
            processor: OWL-ViTãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
            outputs: æ¨è«–çµæœ
            target_sizes: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚º
            confidence_threshold: ä¿¡é ¼åº¦ã®é–¾å€¤
            
        Returns:
            å¾Œå‡¦ç†ã•ã‚ŒãŸçµæœã€å¤±æ•—æ™‚ã¯None
        """
        try:
            if st.session_state.get('debug_mode', True):
                st.write(f"**ğŸ”§ å¾Œå‡¦ç†å®Ÿè¡Œä¸­ (é–¾å€¤: {confidence_threshold:.3f})...**")
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªå¾Œå‡¦ç†
            results = processor.post_process_object_detection(
                outputs=outputs,
                threshold=confidence_threshold,
                target_sizes=target_sizes
            )
            
            # å¾Œå‡¦ç†çµæœã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            if st.session_state.get('debug_mode', True) and results and len(results) > 0:
                total_boxes = sum(len(result.get("boxes", [])) for result in results)
                st.write(f"- æ¤œå‡ºã•ã‚ŒãŸãƒœãƒƒã‚¯ã‚¹æ•°: {total_boxes}")
                
                for i, result in enumerate(results):
                    boxes = result.get("boxes", [])
                    scores = result.get("scores", [])
                    if len(boxes) > 0:
                        st.write(f"- ã‚¯ã‚¨ãƒª {i+1}: {len(boxes)}å€‹ã®ãƒœãƒƒã‚¯ã‚¹")
                        st.write(f"  - æœ€é«˜ã‚¹ã‚³ã‚¢: {max(scores):.4f}")
                        st.write(f"  - å¹³å‡ã‚¹ã‚³ã‚¢: {sum(scores)/len(scores):.4f}")
                    else:
                        st.write(f"- ã‚¯ã‚¨ãƒª {i+1}: æ¤œå‡ºãªã—")
            elif st.session_state.get('debug_mode', True):
                st.write("- æ¤œå‡ºã•ã‚ŒãŸãƒœãƒƒã‚¯ã‚¹: 0å€‹")
            
            if st.session_state.get('debug_mode', True):
                st.write("âœ… å¾Œå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return results
        except Exception as e:
            st.error(f"çµæœã®å¾Œå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            if st.session_state.get('debug_mode', True):
                st.write(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {str(e)}")
            return None


class ImageGuidedDetectionProcessor:
    """ç”»åƒã‚¬ã‚¤ãƒ‰æ¤œå‡ºã®å‡¦ç†ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def prepare_image_guided_inputs(
        processor: Any,
        image: Any,
        query_image: Any
    ) -> Optional[Dict[str, Any]]:
        """
        ç”»åƒã‚¬ã‚¤ãƒ‰æ¤œå‡ºã®å…¥åŠ›ã‚’æº–å‚™ã—ã¾ã™
        
        Args:
            processor: OWL-ViTãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
            image: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ
            query_image: ã‚¯ã‚¨ãƒªç”»åƒ
            
        Returns:
            æº–å‚™ã•ã‚ŒãŸå…¥åŠ›ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            inputs = processor(
                images=image,
                query_images=query_image,
                return_tensors="pt"
            )
            return inputs
        except Exception as e:
            st.error(f"ç”»åƒã‚¬ã‚¤ãƒ‰æ¤œå‡ºã®å…¥åŠ›æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None
    
    @staticmethod
    def run_image_guided_inference(
        model: OwlViTForObjectDetection,
        inputs: Dict[str, Any]
    ) -> Optional[Any]:
        """
        ç”»åƒã‚¬ã‚¤ãƒ‰æ¤œå‡ºã®æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™
        
        Args:
            model: OWL-ViTãƒ¢ãƒ‡ãƒ«
            inputs: ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›
            
        Returns:
            æ¨è«–çµæœã€å¤±æ•—æ™‚ã¯None
        """
        try:
            with torch.no_grad():
                outputs = model.image_guided_detection(**inputs)
            return outputs
        except Exception as e:
            st.error(f"ç”»åƒã‚¬ã‚¤ãƒ‰æ¤œå‡ºã®æ¨è«–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None
    
    @staticmethod
    def post_process_image_guided_results(
        processor: Any,
        outputs: Any,
        target_sizes: torch.Tensor,
        confidence_threshold: float = 0.5,
        nms_threshold: float = 0.3
    ) -> Optional[List[Dict[str, Any]]]:
        """
        ç”»åƒã‚¬ã‚¤ãƒ‰æ¤œå‡ºã®çµæœã‚’å¾Œå‡¦ç†ã—ã¾ã™
        
        Args:
            processor: OWL-ViTãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
            outputs: æ¨è«–çµæœ
            target_sizes: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚º
            confidence_threshold: ä¿¡é ¼åº¦ã®é–¾å€¤
            nms_threshold: NMSã®é–¾å€¤
            
        Returns:
            å¾Œå‡¦ç†ã•ã‚ŒãŸçµæœã€å¤±æ•—æ™‚ã¯None
        """
        try:
            results = processor.post_process_image_guided_detection(
                outputs=outputs,
                threshold=confidence_threshold,
                nms_threshold=nms_threshold,
                target_sizes=target_sizes
            )
            return results
        except Exception as e:
            st.error(f"ç”»åƒã‚¬ã‚¤ãƒ‰æ¤œå‡ºã®çµæœå¾Œå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None 