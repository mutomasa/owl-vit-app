# 🦉 OWL-ViT Streamlit Application

このアプリケーションは、OWL-ViT（Vision Transformer for Open-World Localization）を使用して物体検出を行うStreamlitアプリケーションです。単一責任原則に従って設計されており、再利用性とテストしやすさを重視しています。

## ✨ 主な機能

### 🎯 検出モード
- **シンプル検出**: 基本的な物体検出（person, car, dog）
- **テキストガイド検出**: テキストクエリで物体を検出
- **画像ガイド検出**: 類似画像で物体を検出

### 🔤 テキスト検索機能
- **手動入力**: 複数のテキストクエリを手動で入力
- **プリセットクエリ**: カテゴリ別のプリセットクエリから選択
- **テキスト検索**: 検索機能とクエリ提案機能
- **カンマ区切り入力**: 複数のクエリを一度に入力可能

### 📷 多様な画像入力
- **サンプル画像**: オフィス、キッチン、リビング、街並み、自然風景
- **画像アップロード**: ローカルファイルをアップロード
- **URL入力**: 画像URLを指定して取得
- **カメラ撮影**: リアルタイムでカメラ撮影

### 🔧 高度な設定
- **デバッグモード**: 詳細な検出情報を表示
- **信頼度閾値**: 自動調整機能付き（0.01-1.0）
- **NMS閾値**: Non-Maximum Suppressionの調整
- **翻訳機能**: 日本語・英語対応

## 🏗️ アーキテクチャ

単一責任原則に従い、以下のモジュールに分離されています：

### モジュール構成

```
owl_vit_app/
├── app.py                 # メインアプリケーション
├── image_processor.py     # 画像処理モジュール
├── model_manager.py       # モデル管理モジュール
├── translator.py          # 翻訳機能モジュール
├── ui_components.py       # UIコンポーネントモジュール
├── pyproject.toml         # プロジェクト設定
├── run_app_uv.sh          # 起動スクリプト
└── README.md             # このファイル
```

### 各モジュールの責任

#### `app.py`
- **OWLViTApp**: メインアプリケーションクラス
- 各モジュールの統合とアプリケーションの制御
- 検出モードの管理

#### `image_processor.py`
- **ImageLoader**: 画像の読み込み（URL、ファイル、カメラ）
- **ImageValidator**: 画像の検証と情報取得
- **ImageVisualizer**: 検出結果の可視化
- **ImagePreprocessor**: 画像の前処理

#### `model_manager.py`
- **ModelLoader**: OWL-ViTモデルとプロセッサーの読み込み
- **TextQueryProcessor**: テキストクエリの処理と検証
- **DetectionProcessor**: テキストガイド検出の処理
- **ImageGuidedDetectionProcessor**: 画像ガイド検出の処理

#### `translator.py`
- **JapaneseTranslator**: 日本語クエリの英語翻訳
- 辞書翻訳とAPI翻訳の両方に対応
- クエリバリエーションの生成

#### `ui_components.py`
- **SidebarManager**: サイドバーの設定UI
- **InputManager**: 入力セクションのUI（画像、テキスト）
- **ResultsManager**: 結果表示のUI

## 🚀 インストール

### uvを使用する場合（推奨）

1. uvをインストール（まだインストールしていない場合）:
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. 依存関係をインストール:
```bash
uv sync
```

3. アプリケーションを起動:
```bash
uv run streamlit run app.py
```

または、起動スクリプトを使用:
```bash
chmod +x run_app_uv.sh
./run_app_uv.sh
```

### pipを使用する場合

1. 仮想環境を作成:
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# または
.venv\Scripts\activate     # Windows
```

2. 依存関係をインストール:
```bash
pip install -e .
```

3. アプリケーションを起動:
```bash
streamlit run app.py
```

## 📖 使用方法

### 1. アプリケーションの起動

上記のインストール手順に従ってアプリケーションを起動し、ブラウザで `http://localhost:8501` にアクセスします。

### 2. 検出モードの選択

サイドバーで以下の検出モードから選択：

- **シンプル検出**: 基本的な物体検出（推奨）
- **テキストガイド検出**: カスタムテキストクエリで検出
- **画像ガイド検出**: 類似画像で検出

### 3. 画像の入力

以下の方法で画像を入力できます：

#### サンプル画像
- オフィスシーン
- キッチンシーン
- リビングルーム
- 街並み
- 自然風景

#### カスタム画像
- **画像アップロード**: ローカルファイルをアップロード
- **URL入力**: 画像URLを指定
- **カメラ撮影**: リアルタイムでカメラ撮影

### 4. テキストクエリの入力（テキストガイド検出）

#### 手動入力
1. クエリ数を設定（1-5個）
2. 各クエリを個別に入力
3. 翻訳方法を選択

#### プリセットクエリ
カテゴリ別のプリセットから選択：
- **動物**: cat, dog, bird, horse, fish, 猫, 犬, 鳥, 馬, 魚
- **乗り物**: car, bicycle, motorcycle, bus, train, 車, 自転車, バイク, バス, 電車
- **家具**: chair, table, sofa, bed, desk, 椅子, テーブル, ソファ, ベッド, 机
- **食べ物**: apple, banana, pizza, cake, bread, りんご, バナナ, ピザ, ケーキ, パン
- **電子機器**: television, computer, smartphone, camera, テレビ, パソコン, スマートフォン, カメラ

#### テキスト検索
1. 検索クエリを入力（カンマ区切り）
2. 検索結果から選択
3. クエリ提案機能を活用

### 5. 設定の調整

サイドバーで以下の設定を調整できます：

- **モデル選択**: 使用するOWL-ViTモデル
- **信頼度閾値**: 検出結果の信頼度閾値（デフォルト: 0.1）
- **NMS閾値**: Non-Maximum Suppressionの閾値
- **デバッグモード**: 詳細な検出情報を表示

### 6. 検出の実行

「物体検出を実行」ボタンをクリックして検出を開始します。

### 7. 結果の確認

- 検出結果が画像上にバウンディングボックスで表示
- 各検出結果の信頼度スコアを表示
- 検出結果画像をダウンロード可能

## 🔧 技術詳細

### OWL-ViTについて

OWL-ViTは、オープンボキャブラリ物体検出のためのVision Transformerモデルです。

**主な特徴:**
- **ゼロショット検出**: 事前に学習した物体クラス以外も検出可能
- **マルチモーダル理解**: テキストと画像の両方を理解
- **CLIPベース**: 強力なマルチモーダル表現学習

**技術仕様:**
- アーキテクチャ: Vision Transformer + CLIP
- 入力: 画像 + テキスト/画像クエリ
- 出力: バウンディングボックス + 信頼度スコア

### 利用可能なモデル

- `google/owlvit-base-patch32`: 基本モデル（推奨）
- `google/owlvit-base-patch16`: 高解像度対応モデル
- `google/owlvit-large-patch14`: 大規模モデル（高精度）

### 翻訳機能

- **辞書翻訳**: 基本的な日本語→英語翻訳
- **API翻訳**: 外部APIを使用した高度な翻訳
- **クエリバリエーション**: 複数のクエリ形式を自動生成

## 🐛 トラブルシューティング

### よくある問題と解決策

#### 検出結果が得られない場合
1. **信頼度閾値を下げる**: サイドバーで0.1以下に設定
2. **テキストクエリを具体的にする**: "cat" ではなく "a photo of a cat"
3. **画像の品質を確認**: 物体が明確に見える画像を使用
4. **デバッグモードを有効にする**: 詳細な情報を確認

#### テンソルサイズエラーが発生する場合
1. **クエリ数を減らす**: 5個以下に制限
2. **シンプル検出モードを使用**: 基本的な検出から開始
3. **画像サイズを小さくする**: 800x800以下にリサイズ

#### モデルの読み込みに失敗する場合
1. **インターネット接続を確認**
2. **ディスク容量を確認**（モデルサイズ: ~1GB）
3. **GPUメモリが不足している場合はCPUモードで実行**

#### メモリ不足エラーが発生する場合
1. **画像サイズを小さくする**
2. **より軽量なモデルを使用**
3. **クエリ数を減らす**

## 🧪 開発

### テスト

```bash
# テストの実行
uv run pytest

# カバレッジ付きテスト
uv run pytest --cov=.
```

### コードフォーマット

```bash
# コードのフォーマット
uv run black .

# リント
uv run flake8 .

# 型チェック
uv run mypy .
```

### アーキテクチャの利点

1. **単一責任原則**: 各クラスが明確な責任を持つ
2. **再利用性**: モジュール間の依存関係が最小限
3. **テストしやすさ**: 各機能が独立してテスト可能
4. **保守性**: 機能の追加・変更が容易
5. **拡張性**: 新しい機能の追加が簡単

## 📝 更新履歴

### v1.0.0 (2024-12-19)
- シンプル検出モードの追加
- テキスト検索機能の実装
- カメラ撮影機能の追加
- デバッグモードの実装
- 信頼度閾値の自動調整機能
- エラーハンドリングの強化
- 多様なサンプル画像の追加

## 📄 ライセンス

このプロジェクトはMITライセンスの下で公開されています。

## 📚 参考資料

- [OWL-ViT Paper](https://arxiv.org/abs/2205.06230)
- [Hugging Face Documentation](https://huggingface.co/docs/transformers/model_doc/owlvit)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [OWL-ViT GitHub Repository](https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit) 

## 🤝 貢献

プルリクエストやイシューの報告を歓迎します。貢献する前に、以下の点を確認してください：

1. コードが既存のスタイルに従っていること
2. 新しい機能にはテストが含まれていること
3. ドキュメントが更新されていること

## 📞 サポート

問題が発生した場合や質問がある場合は、GitHubのイシューを作成してください。 